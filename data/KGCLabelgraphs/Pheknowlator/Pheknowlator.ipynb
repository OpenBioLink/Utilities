{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import wget\n",
    "import bz2\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import rdflib\n",
    "import zipfile\n",
    "from rdflib import Namespace\n",
    "from rdflib.term import URIRef\n",
    "from os.path import exists\n",
    "from rdflib.namespace import DC, DCTERMS, DOAP, FOAF, SKOS, OWL, RDF, RDFS, VOID, XMLNS, XSD\n",
    "\n",
    "#create this bar_progress method which is invoked automatically from wget\n",
    "def bar_progress(current, total, width=80):\n",
    "  progress_message = \"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n",
    "  # Don't use print() as it will print in new line every time.\n",
    "  sys.stdout.write(\"\\r\" + progress_message)\n",
    "  sys.stdout.flush()\n",
    "\n",
    "  # Methods\n",
    "def read_nodes(lst):\n",
    "    nodes = set()\n",
    "    for path in lst:\n",
    "        content = None\n",
    "        with open(path, encoding=\"utf8\") as f:\n",
    "            content = f.readlines()\n",
    "        content = [x.strip() for x in content]\n",
    "\n",
    "        for line in content:\n",
    "            head,rel,tail = line.split(\"\\t\")\n",
    "            nodes.add(head)\n",
    "            nodes.add(tail)\n",
    "    return nodes\n",
    "\n",
    "def read_line(path, skip_first):\n",
    "    with open(path, encoding=\"utf8\") as infile:\n",
    "        c = 0\n",
    "        while True:\n",
    "            line = infile.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            if c % 100000 == 0:\n",
    "                print(c)\n",
    "            c += 1\n",
    "            if skip_first and c == 0:\n",
    "                continue\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path setup\n",
    "train_path = r\"cache\\train.txt\"\n",
    "test_path = r\"cache\\test.txt\"\n",
    "valid_path = r\"cache\\valid.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100% [207682562 / 207682562] bytes"
     ]
    }
   ],
   "source": [
    "if not exists('cache'):\n",
    "    os.makedirs('cache')\n",
    "\n",
    "if not exists('cache/labels.txt'):\n",
    "    url = \"https://storage.googleapis.com/pheknowlator/archived_builds/release_v2.0.0/build_11FEB2021/knowledge_graphs/instance_builds/relations_only/owlnets/PheKnowLator_v2.0.0_full_instance_relationsOnly_OWLNETS_NodeLabels.txt\"\n",
    "    wget.download(url, 'cache/labels.txt', bar=bar_progress)\n",
    "\n",
    "if not exists('cache/train.txt'):\n",
    "    url = \"https://github.com/OpenBioLink/Utilities/raw/main/data/Pheknowlator/data.zip\"\n",
    "    wget.download(url, 'cache/data.zip', bar=bar_progress)\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile('cache/data.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('cache')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ai = Namespace(\"http://ai-strategies.org/ns/\")\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.bind(\"ai\", ai)\n",
    "g.bind(\"rdf\", RDF)\n",
    "g.bind(\"rdfs\", RDFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n"
     ]
    }
   ],
   "source": [
    "for line in read_line('cache/labels.txt', skip_first = True):\n",
    "    try:\n",
    "        cols = line.split(\"\\t\")\n",
    "        if len(cols) == 5:\n",
    "            # some rows are erroneous\n",
    "            entity_type, integer_id, entity_uri, label, description = cols\n",
    "            print(\"ONLY 5 cols\")\n",
    "            print(line)\n",
    "        elif len(cols) ==6:\n",
    "            # normal row\n",
    "            entity_type, integer_id, entity_uri, label, description, synonym = cols\n",
    "        else:\n",
    "            print(\"SKIPPED\")\n",
    "            print(line)\n",
    "            continue\n",
    "        \n",
    "        entity_uri = entity_uri[1:-1]\n",
    "\n",
    "        if entity_type == \"NODES\":\n",
    "            g.add((\n",
    "                URIRef(entity_uri),\n",
    "                RDFS.label,\n",
    "                rdflib.Literal(label, datatype=XSD.string)\n",
    "\n",
    "            ))\n",
    "            g.add((\n",
    "                URIRef(entity_uri),\n",
    "                RDF.type,\n",
    "                rdflib.Literal(\"Entity\", datatype=XSD.string)\n",
    "            ))\n",
    "\n",
    "            g.add((\n",
    "                URIRef(entity_uri),\n",
    "                ai.wwwresource,\n",
    "                rdflib.Literal(entity_uri, datatype=XSD.string)\n",
    "            ))\n",
    "\n",
    "            g.add((\n",
    "                URIRef(entity_uri),\n",
    "                RDFS.comment,\n",
    "                rdflib.Literal(description, datatype=XSD.string)\n",
    "            ))\n",
    "        elif entity_type == \"RELATIONS\":\n",
    "            g.add((\n",
    "                URIRef(entity_uri),\n",
    "                RDFS.label,\n",
    "                rdflib.Literal(label, datatype=XSD.string)\n",
    "            ))\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        print(line)\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.serialize(os.path.abspath(r\"pheknowlator.ttl\"),format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(r\"pheknowlator.ttl\", 'a')\n",
    "\n",
    "def read_set(path, typ):\n",
    "    content = None\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    for line in content:\n",
    "        head,rel,tail = line.split(\"\\t\")\n",
    "        outfile.write(f\"<<{head} {rel} {tail}>> ai:split ai:{typ} . \" + \"\\n\")\n",
    "\n",
    "read_set(train_path, 'train')\n",
    "read_set(test_path, 'test')\n",
    "read_set(valid_path, 'valid')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipObj = zipfile.ZipFile('data.zip', 'w')\n",
    "zipObj.write('pheknowlator.ttl', 'pheknowlator.ttl', zipfile.ZIP_DEFLATED)\n",
    "zipObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6034a6f5458e8007054679e0d1bec28e1df169f2230ff36b046fe759a4786f17"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
