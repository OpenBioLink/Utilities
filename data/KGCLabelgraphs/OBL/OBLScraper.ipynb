{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "import rdflib\n",
    "from rdflib import Namespace\n",
    "from rdflib.namespace import DC, DCTERMS, DOAP, FOAF, SKOS, OWL, RDF, RDFS, VOID, XMLNS, XSD\n",
    "\n",
    "def load_text_file(path):\n",
    "    content = None\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    return content\n",
    "\n",
    "def load_tsv_id_file(path):\n",
    "    content = load_text_file(path)\n",
    "    ids2label = dict()\n",
    "    for line in content:\n",
    "        try:\n",
    "            code, label = line.split(\"\\t\")\n",
    "        except:\n",
    "            print(line)\n",
    "        ids2label[code] = label\n",
    "    return ids2label\n",
    "\n",
    "def add_node(node):\n",
    "    all_nodes.add(node)\n",
    "    if node.startswith(\"NCBIGENE:\"):\n",
    "        ncbigenes.add(node[len(\"NCBIGENE:\"):])\n",
    "    elif node.startswith(\"PUBCHEM.COMPOUND:\"):\n",
    "        pubchemcompounds.add(node[len(\"PUBCHEM.COMPOUND:\"):])\n",
    "    elif node.startswith(\"CL:\"):\n",
    "        clss.add(node)\n",
    "    elif node.startswith(\"GO:\"):\n",
    "        gos.add(node)\n",
    "    elif node.startswith(\"UBERON:\"):\n",
    "        uberons.add(node)\n",
    "    elif node.startswith(\"DOID:\"):\n",
    "        doids.add(node)\n",
    "    elif node.startswith(\"HP:\"):\n",
    "        hps.add(node)\n",
    "    elif node.startswith(\"KEGG:\"):\n",
    "        keggs.add(node)\n",
    "    elif node.startswith(\"REACTOME:\"):\n",
    "        reactomes.add(node)\n",
    "        \n",
    "def read_nodes(path):\n",
    "    content = None\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "\n",
    "    for line in content:\n",
    "        head,rel,tail,_,_ = line.split(\"\\t\")\n",
    "        add_node(head)\n",
    "        add_node(tail)\n",
    "        \n",
    "def divide_chunks(l, n):\n",
    "    l = list(l)\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = r\"./workspace/labels\"\n",
    "graph_path = r\"./workspace/graphs\"\n",
    "edge_path = r\"C:\\Users\\ottsi\\Downloads\\HQ_DIR\\graph_files\\edges.csv\"\n",
    "\n",
    "train_path = r\"C:\\Users\\ottsi\\OneDrive\\MedUni\\OpenBioLink\\SAFRAN\\Evaluations\\OBL\\train.txt\"\n",
    "valid_path = r\"C:\\Users\\ottsi\\OneDrive\\MedUni\\OpenBioLink\\SAFRAN\\Evaluations\\OBL\\valid.txt\"\n",
    "test_path = r\"C:\\Users\\ottsi\\OneDrive\\MedUni\\OpenBioLink\\SAFRAN\\Evaluations\\OBL\\test.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read nodes from graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = set()\n",
    "ncbigenes = set()\n",
    "clss = set()\n",
    "uberons = set()\n",
    "gos = set()\n",
    "doids = set()\n",
    "hps = set()\n",
    "pubchemcompounds = set()\n",
    "keggs = set()\n",
    "reactomes = set()\n",
    "\n",
    "read_nodes(edge_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCBIGENE, PUBCHEM.COMPOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file = open(f\"{labels_path}/obl_labels.txt\", \"w\", encoding=\"utf8\")\n",
    "descr_file = open(f\"{labels_path}/obl_descriptions.txt\", \"w\", encoding=\"utf8\")"
   ]
  },
  {
   "source": [
    "## GENE"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 19598/19598 [02:59<00:00, 108.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ontology = \"gene\"\n",
    "step_size = 500\n",
    "\n",
    "results = dict()\n",
    "count = 0\n",
    "ids_str = \"\"\n",
    "for x in tqdm(ncbigenes):\n",
    "    ids_str = ids_str + str(x) + \",\"\n",
    "    count = count + 1\n",
    "    if count >= step_size:\n",
    "        ids_str = ids_str[0:-1]\n",
    "        response = requests.post(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db={ontology}&rettype=docsum&retmode=json\", data={'id':f'{ids_str}'}, headers={'content-type': 'application/x-www-form-urlencoded'})\n",
    "        response_json = response.json()\n",
    "        for key,value in response_json[\"result\"].items():\n",
    "            if key != 'uids':\n",
    "                results[key] = value\n",
    "        ids_str = \"\"\n",
    "        count = 0\n",
    "\n",
    "if count > 0:\n",
    "    response = requests.post(f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db={ontology}&rettype=docsum&retmode=json\", data={'id':f'{ids_str}'}, headers={'content-type': 'application/x-www-form-urlencoded'})\n",
    "    response_json = response.json()\n",
    "    for key,value in response_json[\"result\"].items():\n",
    "            if key != 'uids':\n",
    "                results[key] = value\n",
    "\n",
    "for x in results:\n",
    "    labels_file.write(\"NCBIGENE:\" + x + \"\\t\" + results[x][\"description\"] + \"\\n\")\n",
    "    if results[x][\"summary\"] != \"\":\n",
    "        descr_file.write(\"NCBIGENE:\" + x + \"\\t\" + results[x][\"summary\"] + \"\\n\")\n"
   ]
  },
  {
   "source": [
    "## COMPOUND"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 77635/77635 [02:37<00:00, 491.83it/s]\n",
      "7402\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ids_str = []\n",
    "step_size = 10000\n",
    "count = 0\n",
    "\n",
    "for x in tqdm(pubchemcompounds):\n",
    "    ids_str.append('{\"cid\":\"' + x + '\"}')\n",
    "    count = count + 1\n",
    "    if count >= step_size:\n",
    "        ids_str = \",\".join(ids_str)\n",
    "        response = requests.post('https://pubchem.ncbi.nlm.nih.gov/sdq/sdqagent.cgi?infmt=json&outfmt=json', data={'query':'{\"select\":\"*\",\"collection\":\"compound\",\"where\":{\"ors\":[' + ids_str + ']},\"order\":[\"cid,asc\"],\"start\":1,\"limit\":10000,\"width\":1000000,\"listids\":0}'}, headers={'content-type': 'application/x-www-form-urlencoded'})\n",
    "        response_json = response.json()\n",
    "        for entry in response_json[\"SDQOutputSet\"][0][\"rows\"]:\n",
    "            labels_file.write(\"PUBCHEM.COMPOUND:\" + str(entry[\"cid\"]) + \"\\t\" + entry[\"cmpdname\"] + \"\\n\")\n",
    "\n",
    "        ids_str = []\n",
    "        count = 0\n",
    "\n",
    "if count > 0:\n",
    "    ids_str = \",\".join(ids_str)\n",
    "    response = requests.post('https://pubchem.ncbi.nlm.nih.gov/sdq/sdqagent.cgi?infmt=json&outfmt=json', data={'query':'{\"select\":\"*\",\"collection\":\"compound\",\"where\":{\"ors\":[' + ids_str + ']},\"order\":[\"cid,asc\"],\"start\":1,\"limit\":10000,\"width\":1000000,\"listids\":0}'}, headers={'content-type': 'application/x-www-form-urlencoded'})\n",
    "    response_json = response.json()\n",
    "\n",
    "    print(len(response_json[\"SDQOutputSet\"][0][\"rows\"]))\n",
    "    for entry in response_json[\"SDQOutputSet\"][0][\"rows\"]:\n",
    "        labels_file.write(\"PUBCHEM.COMPOUND:\" + str(entry[\"cid\"]) + \"\\t\" + entry[\"cmpdname\"] + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "7764it [3:39:33,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PUBCHEM.COMPOUND\n",
    "https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/1983,1984/description/JSON\n",
    "https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/1983,1984/synonyms/JSON\n",
    "\"\"\"\n",
    "\n",
    "json_file = open(f\"{labels_path}/compound.txt\", \"w\")\n",
    "json_file.write(\"[\\n\")\n",
    "results = []\n",
    "for x in tqdm(divide_chunks(pubchemcompounds, 10), total=int(len(pubchemcompounds)/10)):\n",
    "    ids_str = \",\".join(x)\n",
    "    response = requests.get(f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{ids_str}/description/JSON\")\n",
    "    response_json = response.json()\n",
    "\n",
    "    results.extend(response_json[\"InformationList\"][\"Information\"])\n",
    "    json_file.write(json.dumps(response_json[\"InformationList\"][\"Information\"]) + \",\\n\")\n",
    "    json_file.flush()\n",
    "\n",
    "json_file.write(\"]\\n\")\n",
    "json_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "jayson = None\n",
    "with open(f\"{labels_path}/compound.txt\") as infile:\n",
    "    jayson = json.load(infile)\n",
    "\n",
    "\n",
    "cids = defaultdict(dict)\n",
    "\n",
    "for part in jayson:\n",
    "    for ele in part:\n",
    "        assert (\"Title\" in ele and \"Description\" not in ele) or (\"Title\" not in ele and \"Description\" in ele), \"Big oof\"\n",
    "        if \"Title\" in ele:\n",
    "            cids[ele[\"CID\"]][\"Title\"] = ele[\"Title\"]\n",
    "        elif \"Description\" in ele:\n",
    "            if \"Description\" not in cids[ele[\"CID\"]]:\n",
    "                cids[ele[\"CID\"]][\"Description\"] = []\n",
    "            cids[ele[\"CID\"]][\"Description\"].append(ele[\"Description\"])\n",
    "        else:\n",
    "            print(\"HM\")\n",
    "            print(ele)\n",
    "\n",
    "import json\n",
    "with open(f'{labels_path}/result.json', 'w') as fp:\n",
    "    json.dump(cids, fp, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = None\n",
    "with open(f'{labels_path}/result.json') as fp:\n",
    "    json_file = json.load(fp)\n",
    "\n",
    "for x in json_file:\n",
    "    labels_file.write(\"PUBCHEM.COMPOUND:\" + x + \"\\t\" + json_file[x][\"Title\"] + \"\\n\")\n",
    "    if \"Description\" in json_file[x] and len(json_file[x][\"Description\"]) > 0:\n",
    "        descr_file.write(\"PUBCHEM.COMPOUND:\" + x + \"\\t\" + json_file[x][\"Description\"][0] + \"\\n\")\n"
   ]
  },
  {
   "source": [
    "## UBERON, HP, GO, DOID, CL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "hp\n",
      "100%|██████████| 53/53 [01:59<00:00,  2.26s/it]\n",
      "uberon\n",
      "100%|██████████| 32/32 [01:33<00:00,  2.93s/it]\n",
      "go\n",
      "100%|██████████| 102/102 [03:34<00:00,  2.10s/it]\n",
      "doid\n",
      "100%|██████████| 36/36 [01:47<00:00,  3.00s/it]\n",
      "cl\n",
      "100%|██████████| 21/21 [00:51<00:00,  2.46s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "uberon, hp, go, doid, cl\n",
    "\n",
    "# to prettify\n",
    "python -m json.tool uberon.txt uberon.json\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for ontology, ids in [(\"hp\", hps), (\"uberon\", uberons), (\"go\", gos), (\"doid\", doids), (\"cl\", clss)]:\n",
    "    print(ontology)\n",
    "    response = requests.get(f\"http://www.ebi.ac.uk/ols/api/ontologies/{ontology}/terms?page=0&size=500\")\n",
    "    totalPages = int(response.json()[\"page\"][\"totalPages\"])\n",
    "    for page in tqdm(range(0,totalPages)):\n",
    "        response = requests.get(f\"http://www.ebi.ac.uk/ols/api/ontologies/{ontology}/terms?page={page}&size=500\")\n",
    "        response_json = response.json()\n",
    "        for x in response_json[\"_embedded\"][\"terms\"]:\n",
    "            if x[\"obo_id\"] in ids:\n",
    "                labels_file.write(x[\"obo_id\"] + \"\\t\" + x[\"label\"] + \"\\n\")\n",
    "                if \"description\" in x and x[\"description\"] != None and len(x[\"description\"]) > 0:\n",
    "                    descr_file.write(x[\"obo_id\"] + \"\\t\" + x[\"description\"][0] + \"\\n\")\n",
    "                elif \"annotation\" in x and x[\"annotation\"] != None:\n",
    "                    if \"definition\" in x[\"annotation\"] and x[\"annotation\"][\"definition\"] != None and len(x[\"annotation\"][\"definition\"]) > 0:\n",
    "                        descr_file.write(x[\"obo_id\"] + \"\\t\" + x[\"annotation\"][\"definition\"][0] + \"\\n\")\n",
    "                elif \"obo_definition_citation\" in x and x[\"obo_definition_citation\"] != None and len(x[\"obo_definition_citation\"]) > 0:\n",
    "                        descr_file.write(x[\"obo_id\"] + \"\\t\" + x[\"obo_definition_citation\"][0][\"definition\"] + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KEGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 345/345 [02:50<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "KEGG\n",
    "KEGG:hsa00232 \n",
    "\n",
    "\"\"\"\n",
    "ontology = \"kegg\"\n",
    "response = requests.get(f\"http://rest.kegg.jp/list/pathway/hsa\")\n",
    "for x in tqdm(response.text.split(\"\\n\")):\n",
    "    if x != \"\":\n",
    "        code, label = x.split(\"\\t\")\n",
    "        code = code.replace(\"path:\", \"KEGG:\")\n",
    "        label = label.split(\" - \")[0]\n",
    "        if code in keggs:\n",
    "            response = requests.get(f\"http://rest.kegg.jp/get/{code.replace('KEGG:', '')}\")\n",
    "            response_text = response.text\n",
    "            response_text = response_text.split(\"\\n\")\n",
    "            for line in response_text:\n",
    "                if line.startswith(\"DESCRIPTION\"):\n",
    "                    descr_file.write(code + \"\\t\" + line[11:].strip() + \"\\n\")\n",
    "            labels_file.write(code + \"\\t\" + label + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REACTOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  4%|▍         | 71/1860 [00:32<14:12,  2.10it/s]EXCEPTION 'name' R-HSA-977442\n",
      "  6%|▌         | 104/1860 [00:45<11:38,  2.51it/s]EXCEPTION 'name' R-HSA-1980148\n",
      "  6%|▌         | 108/1860 [00:46<10:18,  2.83it/s]EXCEPTION 'name' R-HSA-629602\n",
      "  6%|▌         | 113/1860 [00:48<11:07,  2.62it/s]EXCEPTION 'name' R-HSA-69298\n",
      "  6%|▋         | 119/1860 [00:51<11:52,  2.44it/s]EXCEPTION 'name' R-HSA-71182\n",
      "  7%|▋         | 122/1860 [00:52<11:35,  2.50it/s]EXCEPTION 'name' R-HSA-194223\n",
      "  7%|▋         | 135/1860 [00:57<11:19,  2.54it/s]EXCEPTION 'name' R-HSA-73847\n",
      "  7%|▋         | 136/1860 [00:58<10:56,  2.63it/s]EXCEPTION 'name' R-HSA-70153\n",
      "  8%|▊         | 143/1860 [01:00<10:54,  2.62it/s]EXCEPTION 'name' R-HSA-1222352\n",
      "  9%|▉         | 167/1860 [01:09<10:08,  2.78it/s]EXCEPTION 'name' R-HSA-428808\n",
      " 10%|█         | 191/1860 [01:19<11:30,  2.42it/s]EXCEPTION 'name' R-HSA-174800\n",
      " 11%|█         | 196/1860 [01:21<11:07,  2.49it/s]EXCEPTION 'name' R-HSA-1980150\n",
      " 11%|█         | 209/1860 [01:26<10:21,  2.66it/s]EXCEPTION 'name' R-HSA-2408517\n",
      " 14%|█▍        | 261/1860 [01:46<09:56,  2.68it/s]EXCEPTION 'name' R-HSA-8855121\n",
      " 14%|█▍        | 268/1860 [01:49<10:30,  2.53it/s]EXCEPTION 'name' R-HSA-975298\n",
      " 17%|█▋        | 308/1860 [02:06<09:40,  2.67it/s]EXCEPTION 'name' R-HSA-168253\n",
      " 19%|█▉        | 354/1860 [02:25<09:59,  2.51it/s]EXCEPTION 'name' R-HSA-70614\n",
      " 21%|██        | 395/1860 [02:42<10:03,  2.43it/s]EXCEPTION 'name' R-HSA-1234162\n",
      " 21%|██▏       | 396/1860 [02:42<09:27,  2.58it/s]EXCEPTION 'name' R-HSA-191647\n",
      " 27%|██▋       | 505/1860 [03:25<08:30,  2.65it/s]EXCEPTION 'name' R-HSA-1300652\n",
      " 31%|███       | 574/1860 [03:53<08:36,  2.49it/s]EXCEPTION 'name' R-HSA-109688\n",
      " 34%|███▎      | 626/1860 [04:14<07:15,  2.83it/s]EXCEPTION 'name' R-HSA-69300\n",
      " 36%|███▌      | 667/1860 [04:30<07:24,  2.69it/s]EXCEPTION 'name' R-HSA-73848\n",
      " 39%|███▉      | 732/1860 [04:56<06:49,  2.75it/s]EXCEPTION 'name' R-HSA-168254\n",
      " 40%|████      | 746/1860 [05:02<07:04,  2.62it/s]EXCEPTION 'name' R-HSA-73923\n",
      " 40%|████      | 747/1860 [05:02<06:51,  2.70it/s]EXCEPTION 'name' R-HSA-68874\n",
      " 48%|████▊     | 887/1860 [06:01<06:28,  2.50it/s]EXCEPTION 'name' R-HSA-442745\n",
      " 48%|████▊     | 891/1860 [06:03<06:02,  2.67it/s]EXCEPTION 'name' R-HSA-421837\n",
      " 48%|████▊     | 901/1860 [06:07<06:19,  2.53it/s]EXCEPTION 'name' R-HSA-171052\n",
      " 49%|████▉     | 914/1860 [06:12<06:10,  2.55it/s]EXCEPTION 'name' R-HSA-2993913\n",
      " 50%|█████     | 930/1860 [06:18<05:50,  2.65it/s]EXCEPTION 'name' R-HSA-69304\n",
      " 57%|█████▋    | 1058/1860 [07:12<05:09,  2.59it/s]EXCEPTION 'name' R-HSA-428790\n",
      " 59%|█████▊    | 1092/1860 [07:26<04:49,  2.65it/s]EXCEPTION 'name' R-HSA-1300644\n",
      " 64%|██████▍   | 1188/1860 [08:07<04:16,  2.62it/s]EXCEPTION 'name' R-HSA-194840\n",
      " 68%|██████▊   | 1274/1860 [08:41<03:37,  2.70it/s]EXCEPTION 'name' R-HSA-211227\n",
      " 70%|███████   | 1308/1860 [08:54<03:41,  2.49it/s]EXCEPTION 'name' R-HSA-157881\n",
      " 71%|███████   | 1317/1860 [08:58<03:27,  2.62it/s]EXCEPTION 'name' R-HSA-265473\n",
      " 76%|███████▋  | 1422/1860 [09:41<02:43,  2.67it/s]EXCEPTION 'name' R-HSA-504046\n",
      " 78%|███████▊  | 1444/1860 [09:50<02:44,  2.53it/s]EXCEPTION 'name' R-HSA-375170\n",
      " 79%|███████▉  | 1465/1860 [09:59<02:32,  2.59it/s]EXCEPTION 'name' R-HSA-203765\n",
      " 80%|███████▉  | 1486/1860 [10:07<02:21,  2.65it/s]EXCEPTION 'name' R-HSA-442717\n",
      " 86%|████████▋ | 1605/1860 [10:56<01:33,  2.73it/s]EXCEPTION 'name' R-HSA-428776\n",
      " 87%|████████▋ | 1623/1860 [11:03<01:31,  2.60it/s]EXCEPTION 'name' R-HSA-2262749\n",
      " 89%|████████▉ | 1660/1860 [11:17<01:18,  2.54it/s]EXCEPTION 'name' R-HSA-997269\n",
      " 90%|████████▉ | 1665/1860 [11:19<01:22,  2.37it/s]EXCEPTION 'name' R-HSA-73777\n",
      " 91%|█████████ | 1695/1860 [11:31<00:59,  2.78it/s]EXCEPTION 'name' R-HSA-977441\n",
      " 92%|█████████▏| 1702/1860 [11:34<00:57,  2.75it/s]EXCEPTION 'name' R-HSA-69229\n",
      " 95%|█████████▍| 1765/1860 [12:00<00:38,  2.47it/s]EXCEPTION 'name' R-HSA-6788656\n",
      " 97%|█████████▋| 1803/1860 [12:16<00:22,  2.49it/s]EXCEPTION 'name' R-HSA-166054\n",
      " 97%|█████████▋| 1806/1860 [12:17<00:21,  2.48it/s]EXCEPTION 'name' R-HSA-5357572\n",
      " 99%|█████████▊| 1835/1860 [12:28<00:09,  2.60it/s]EXCEPTION 'name' R-HSA-535734\n",
      "100%|██████████| 1860/1860 [12:38<00:00,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "for code in tqdm(reactomes):\n",
    "    code = code.replace(\"REACTOME:\", \"\")\n",
    "    response = requests.get(f\"https://reactome.org/ContentService/data/query/{code}\")\n",
    "    try:\n",
    "        response_json = response.json()\n",
    "        labels_file.write(\"REACTOME:\" + code + \"\\t\" + response_json[\"name\"][0] + \"\\n\")\n",
    "\n",
    "        if \"summation\" in response_json and response_json[\"summation\"] != None:\n",
    "            descr_file.write(\"REACTOME:\" + code + \"\\t\" + response_json[\"summation\"][0][\"text\"] + \"\\n\")\n",
    "        else:\n",
    "            print(code)\n",
    "    except Exception as e:\n",
    "        print(f\"EXCEPTION {e} {code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_file.close()\n",
    "descr_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDF graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "identifiers = Namespace(\"http://identifiers.org/\")\n",
    "OBO = Namespace(\"http://www.geneontology.org/formats/oboInOwl#\")\n",
    "ai = Namespace(\"http://ai-strategies.org/ns/\")\n",
    "\n",
    "g = rdflib.Graph()\n",
    "\n",
    "g.bind(\"id\", identifiers)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"oboInOwl\", OBO)\n",
    "g.bind(\"ai\", ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|          | 1219/184667 [00:00<00:30, 6108.13it/s]\n",
      "100%|██████████| 184667/184667 [00:33<00:00, 5550.32it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ids2label = load_tsv_id_file(\"./workspace/labels/obl_labels.txt\")\n",
    "ids2descr = load_tsv_id_file(\"./workspace/labels/obl_descriptions.txt\")\n",
    "\n",
    "for node in tqdm(all_nodes):\n",
    "\n",
    "    type = \"\"\n",
    "    if node.startswith(\"NCBIGENE:\"):\n",
    "        type = \"Gene\"\n",
    "    elif node.startswith(\"PUBCHEM.COMPOUND:\"):\n",
    "        type = \"Drug\"\n",
    "    elif node.startswith(\"UBERON:\"):\n",
    "        type = \"Anatomy\"\n",
    "    elif node.startswith(\"DOID:\"):\n",
    "        type = \"Disease\"\n",
    "    elif node.startswith(\"GO:\"):\n",
    "        type = \"GO\"\n",
    "    elif node.startswith(\"HP:\"):\n",
    "        type = \"Phenotype\"\n",
    "    elif node.startswith(\"CL:\"):\n",
    "        type = \"Anatomy\"\n",
    "    elif node.startswith(\"KEGG:\"):\n",
    "        type = \"Pathway\"\n",
    "    elif node.startswith(\"REACTOME:\"):\n",
    "        type = \"Pathway\"\n",
    "    \n",
    "    if node in ids2label:\n",
    "        g.add((\n",
    "            identifiers.term(node),\n",
    "            RDFS.label,\n",
    "            rdflib.Literal(ids2label[node], datatype=XSD.string)\n",
    "        ))\n",
    "\n",
    "        g.add((\n",
    "            identifiers.term(node),\n",
    "            RDF.type,\n",
    "            rdflib.Literal(type, datatype=XSD.string)\n",
    "        ))\n",
    "\n",
    "        g.add((\n",
    "            identifiers.term(node),\n",
    "            ai.wwwresource,\n",
    "            rdflib.Literal(\"http://identifiers.org/\" + node, datatype=XSD.string)\n",
    "        ))\n",
    "\n",
    "        if node in ids2descr:\n",
    "            g.add((\n",
    "                identifiers.term(node),\n",
    "                RDFS.comment,\n",
    "                rdflib.Literal(ids2descr[node], datatype=XSD.string)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = {\n",
    "    \"GENE_PHENOTYPE\": \"associated with\",\n",
    "    \"GENE_EXPRESSED_ANATOMY\": \"is expressed in\",\n",
    "    \"GENE_BINDING_GENE\": \"is in an binding interaction with\",\n",
    "    \"GENE_UNDEREXPRESSED_ANATOMY\": \"can be underexpressed in\",\n",
    "    \"GENE_GENE\": \"is in an interaction with\",\n",
    "    \"GENE_REACTION_GENE\": \"is in a reaction with\",\n",
    "    \"DRUG_REACTION_GENE\": \"is reacting with\",\n",
    "    \"GENE_GO\": \"associated with\",\n",
    "    \"GENE_PATHWAY\": \"is part of pathway\",\n",
    "    \"GENE_OVEREXPRESSED_ANATOMY\": \"can be overexpressed in\",\n",
    "    \"GENE_DRUG\": \"associated with\",\n",
    "    \"DRUG_CATALYSIS_GENE\": \"is catalyzed by\",\n",
    "    \"DRUG_BINDING_GENE\": \"is binding to\",\n",
    "    \"PART_OF\": \"is part of\",\n",
    "    \"GENE_INHIBITION_GENE\": \"is in an inhibition interaction with\",\n",
    "    \"DRUG_INHIBITION_GENE\": \"is inhibiting\",\n",
    "    \"DRUG_PHENOTYPE\": \"can cause\",\n",
    "    \"IS_A\": \"is a\",\n",
    "    \"GENE_CATALYSIS_GENE\": \"is in an catalysis interaction with\",\n",
    "    \"GENE_ACTIVATION_GENE\": \"is in an activation interaction with\",\n",
    "    \"DIS_DRUG\": \"treated with (indication)\",\n",
    "    \"DRUG_ACTIVATION_GENE\": \"is activating\",\n",
    "    \"DIS_PHENOTYPE\": \"has overservable characteristic\",\n",
    "    \"GENE_PTMOD_GENE\": \"is in an ptmod interaction with\",\n",
    "    \"DRUG_BINDINH_GENE\": \"is binding to and inhibiting\",\n",
    "    \"GENE_DIS\": \"associated with\",\n",
    "    \"DRUG_BINDACT_GENE\": \"is binding to and activating\",\n",
    "    \"GENE_EXPRESSION_GENE\": \"is in an expression interaction with\"\n",
    "}\n",
    "\n",
    "for relation, label in relations.items():\n",
    "    g.add((\n",
    "        identifiers.term(relation),\n",
    "        RDFS.label,\n",
    "        rdflib.Literal(label, datatype=XSD.string)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialize graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g.serialize(graph_path + \"/obl_with_labels.ttl\",format=\"turtle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = open(graph_path + \"/obl_with_labels.ttl\", 'a')\n",
    "\n",
    "def read_set(path, typ):\n",
    "    content = None\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "    for line in content:\n",
    "        head,rel,tail = line.split(\"\\t\")\n",
    "        outfile.write(f\"<<<http://identifiers.org/{head}> <http://identifiers.org/{rel}> <http://identifiers.org/{tail}>>> ai:split ai:{typ} . \" + \"\\n\")\n",
    "\n",
    "read_set(train_path, 'train')\n",
    "read_set(test_path, 'test')\n",
    "read_set(valid_path, 'valid')\n",
    "\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "e7c37ba80a6e54a3d63188245ab5de6a3e0d381993bcb1990a7020536fc2299e"
   }
  },
  "interpreter": {
   "hash": "975f4df5516a56fef896b4876c749fefbbf20f04919a2b7836d7dfd2ac100f7a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}